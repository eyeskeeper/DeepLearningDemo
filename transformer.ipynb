{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0fce2ac",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]]])\n",
      "torch.Size([2, 4, 1])\n",
      "tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# word embedding 以序列建模为例子\n",
    "# 构建序列，序列的字符以其在词表中的索引的形式表示\n",
    "# 考虑source sentence 和 target sentence\n",
    "\n",
    "\n",
    "batch_size = 2\n",
    "# 单词长度\n",
    "max_src_num_words = 8\n",
    "max_tgt_num_words = 8\n",
    "\n",
    "# 序列最大长度\n",
    "max_src_seq_len = 5\n",
    "max_tgt_seq_len = 5\n",
    "max_position_len = 5\n",
    "model_dim = 8   # 512\n",
    "# src_len = torch.randint(2, 5, (batch_size,))\n",
    "# tgt_len = torch.randint(2, 5, (batch_size,))\n",
    "\n",
    "# 原序列长度分别为2和4\n",
    "# 目标序列长度为4和3\n",
    "src_len = torch.Tensor([2, 4]).to(torch.int32)\n",
    "tgt_len = torch.Tensor([4, 3]).to(torch.int32)\n",
    "\n",
    "\n",
    "# step1: 生成原序列和目标序列\n",
    "# 单词索引构成的句子(同时使用F.pad)\n",
    "# 把每一个句子变成二维然后在第0维cat\n",
    "src_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(1, max_src_num_words, (L,)), (0, max(src_len)-L)), 0) for L in src_len])\n",
    "tgt_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(1, max_tgt_num_words, (L,)), (0, max(tgt_len)-L)), 0) for L in tgt_len])\n",
    "\n",
    "#step2: 构造embedding(+1是因为padding的0不在字符表中)\n",
    "src_embedding_table = nn.Embedding(max_src_num_words+1, model_dim)\n",
    "tgt_embedding_table = nn.Embedding(max_tgt_num_words+1, model_dim)\n",
    "\n",
    "src_embedding = src_embedding_table(src_seq)\n",
    "tgt_embedding = tgt_embedding_table(tgt_seq)\n",
    "\n",
    "# step3: 构建position embedding\n",
    "post_mat = torch.arange(max_position_len).reshape((-1, 1))\n",
    "i_mat = torch.pow(10000, torch.arange(0, 8, 2).reshape((1, -1))/model_dim)\n",
    "pe_embedding_table = torch.zeros(max_position_len, model_dim)\n",
    "pe_embedding_table[:, 0::2] = torch.sin(post_mat/i_mat)\n",
    "pe_embedding_table[:, 1::2] = torch.cos(post_mat/i_mat)\n",
    "# print(pe_embedding_table)\n",
    "\n",
    "pe_embedding = nn.Embedding(max_position_len, model_dim)\n",
    "pe_embedding.weight = nn.Parameter(pe_embedding_table, requires_grad=False)\n",
    "# print(pe_embedding.weight)\n",
    "\n",
    "# 输出【【0，1，2，3】【0，1，2，3】】\n",
    "src_pos = torch.cat([torch.unsqueeze(torch.arange(max(src_len)),0) for _ in src_len]).to(torch.int32)\n",
    "tgt_pos = torch.cat([torch.unsqueeze(torch.arange(max(tgt_len)),0) for _ in tgt_len]).to(torch.int32)\n",
    "# print(src_pos)\n",
    "# print(tgt_pos)\n",
    "src_pe_emnedding = pe_embedding(src_pos)\n",
    "tgt_pe_emnedding = pe_embedding(tgt_pos)\n",
    "# print(src_pe_emnedding)\n",
    "# print(tgt_pe_emnedding)\n",
    "\n",
    "# step4: 构建encoder的self-attention mask (构建原因：不知道句子的具体长度，对于padding的部分需要进行掩码处理)\n",
    "# mask 的 shape [batchsize, max_src_len, max_src_len]  值为1或-inf\n",
    "\n",
    "valid_encoder_pos =torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0,max(src_len)-L)),0) for L in src_len ])\n",
    "valid_encoder_pos = torch.unsqueeze(valid_encoder_pos,2)\n",
    "print(valid_encoder_pos)\n",
    "print(valid_encoder_pos.shape)\n",
    "\n",
    "valid_encoder_pos_matrix =torch.bmm(valid_encoder_pos, valid_encoder_pos.transpose(1,2))\n",
    "print(valid_encoder_pos_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc8f078",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "由于第一个句子长度为2，所以第一个单词与第一第二个单词能建立联系，所以矩阵为1，1，0，0。其他行同理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7589940a",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(src_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf8c0b23",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[False, False,  True,  True],\n",
      "         [False, False,  True,  True],\n",
      "         [ True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True]],\n",
      "\n",
      "        [[False, False, False, False],\n",
      "         [False, False, False, False],\n",
      "         [False, False, False, False],\n",
      "         [False, False, False, False]]])\n"
     ]
    }
   ],
   "source": [
    "# 得到需要被mask的位置\n",
    "invalid_encoder_pos_matrix = 1- valid_encoder_pos_matrix\n",
    "mask_ecodner_selfattention_matrix = invalid_encoder_pos_matrix.to(torch.bool)\n",
    "print(mask_ecodner_selfattention_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f86e278",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2359,  0.2242,  0.3788, -0.1779],\n",
      "         [ 0.1949, -1.7529,  0.0588, -0.6717],\n",
      "         [-0.0459,  1.8927, -0.2315, -0.4335],\n",
      "         [-0.2519,  1.6211, -1.6212, -0.1008]],\n",
      "\n",
      "        [[ 1.0812,  0.2933,  1.1187,  0.1584],\n",
      "         [ 1.4733, -0.4585,  0.0456, -0.1305],\n",
      "         [-1.2709, -0.5012,  0.9085,  0.2950],\n",
      "         [-0.9198,  0.0420,  1.0917, -0.3686]]])\n"
     ]
    }
   ],
   "source": [
    "# 模拟得到的score\n",
    "score = torch.randn(batch_size, max(src_len), max(src_len))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc2ba273",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-2.3590e-01,  2.2422e-01,  1.0000e-09,  1.0000e-09],\n",
      "         [ 1.9492e-01, -1.7529e+00,  1.0000e-09,  1.0000e-09],\n",
      "         [ 1.0000e-09,  1.0000e-09,  1.0000e-09,  1.0000e-09],\n",
      "         [ 1.0000e-09,  1.0000e-09,  1.0000e-09,  1.0000e-09]],\n",
      "\n",
      "        [[ 1.0812e+00,  2.9331e-01,  1.1187e+00,  1.5838e-01],\n",
      "         [ 1.4733e+00, -4.5854e-01,  4.5614e-02, -1.3045e-01],\n",
      "         [-1.2709e+00, -5.0124e-01,  9.0853e-01,  2.9504e-01],\n",
      "         [-9.1982e-01,  4.2036e-02,  1.0917e+00, -3.6862e-01]]])\n",
      "tensor([[[0.1955, 0.3096, 0.2475, 0.2475],\n",
      "         [0.3586, 0.0511, 0.2951, 0.2951],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500]],\n",
      "\n",
      "        [[0.3460, 0.1573, 0.3592, 0.1375],\n",
      "         [0.6306, 0.0914, 0.1512, 0.1268],\n",
      "         [0.0596, 0.1286, 0.5267, 0.2852],\n",
      "         [0.0780, 0.2040, 0.5827, 0.1353]]])\n"
     ]
    }
   ],
   "source": [
    "mask_score = score.masked_fill(mask_ecodner_selfattention_matrix, 1e-9)\n",
    "print(mask_score)\n",
    "prob = F.softmax(mask_score, -1)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80422bcc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]]])\n",
      "tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.]]])\n",
      "tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [1., 1., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "# step5: intra_attention_mask\n",
    "# Q*K^T  shape [batch_size, tgt_seq_len, src_seq_len]\n",
    "valid_encoder_pos =torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0,max(src_len)-L)),0) for L in src_len ]), 2)\n",
    "valid_decoder_pos =torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0,max(tgt_len)-L)),0) for L in tgt_len ]), 2)\n",
    "# 表明原序列和目标序列的相关性\n",
    "valid_cross_pos =torch.bmm(valid_decoder_pos, valid_encoder_pos.transpose(1, 2))\n",
    "print(valid_encoder_pos)\n",
    "print(valid_decoder_pos)\n",
    "print(valid_cross_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1eb1b1d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 1., 1.],\n",
      "         [0., 0., 1., 1.],\n",
      "         [0., 0., 1., 1.],\n",
      "         [0., 0., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "tensor([[[ True,  True, False, False],\n",
      "         [ True,  True, False, False],\n",
      "         [ True,  True, False, False],\n",
      "         [ True,  True, False, False]],\n",
      "\n",
      "        [[ True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True],\n",
      "         [False, False, False, False]]])\n",
      "tensor([[[0.0000, 0.0000, 0.6357, 0.3643],\n",
      "         [0.0000, 0.0000, 0.6749, 0.3251],\n",
      "         [0.0000, 0.0000, 0.5503, 0.4497],\n",
      "         [0.0000, 0.0000, 0.1794, 0.8206]],\n",
      "\n",
      "        [[0.2500, 0.2500, 0.2500, 0.2500],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500],\n",
      "         [0.0780, 0.2040, 0.5827, 0.1353]]])\n"
     ]
    }
   ],
   "source": [
    "invalid_cross_pos = 1-valid_cross_pos \n",
    "print(invalid_cross_pos)\n",
    "mask_cross_attention = valid_cross_pos.to(torch.bool)\n",
    "print(mask_cross_attention)\n",
    "\n",
    "encoder_mask_score = score.masked_fill(mask_cross_attention, -1e9)\n",
    "encode_prob = F.softmax(encoder_mask_score, -1)\n",
    "print(encode_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8769cf83",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 0., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [1., 1., 1., 0.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [1., 1., 1., 0.],\n",
      "         [0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "# step6:decoder self-attention_mask构建\n",
    "valid_decoder_tri_matrix = torch.cat([torch.unsqueeze(F.pad(torch.tril(torch.ones((L,L))),(0,max(tgt_len)-L,0,max(tgt_len)-L)),0)\\\n",
    "                                      for L in tgt_len])\n",
    "print(valid_decoder_tri_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f83847a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[False,  True,  True,  True],\n",
      "         [False, False,  True,  True],\n",
      "         [False, False, False,  True],\n",
      "         [False, False, False, False]],\n",
      "\n",
      "        [[False,  True,  True,  True],\n",
      "         [False, False,  True,  True],\n",
      "         [False, False, False,  True],\n",
      "         [ True,  True,  True,  True]]])\n"
     ]
    }
   ],
   "source": [
    "invalid_decoder_tri_matrix = 1- valid_decoder_tri_matrix\n",
    "invalid_decoder_tri_matrix = invalid_decoder_tri_matrix.to(torch.bool)\n",
    "print(invalid_decoder_tri_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92555fa3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 9.3735e-02, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [ 5.9159e-01, -1.6989e+00, -1.0000e+09, -1.0000e+09],\n",
      "         [-5.6981e-02, -5.7947e-01,  1.3748e+00, -1.0000e+09],\n",
      "         [ 1.1662e-01,  1.0154e+00, -5.7117e-01,  4.5714e-01]],\n",
      "\n",
      "        [[ 9.4912e-01, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [-1.0390e+00,  2.1273e+00, -1.0000e+09, -1.0000e+09],\n",
      "         [ 8.1318e-01,  7.0122e-04,  1.0762e+00, -1.0000e+09],\n",
      "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09]]])\n",
      "tensor([[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.9081, 0.0919, 0.0000, 0.0000],\n",
      "         [0.1730, 0.1026, 0.7244, 0.0000],\n",
      "         [0.1864, 0.4579, 0.0937, 0.2620]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0405, 0.9595, 0.0000, 0.0000],\n",
      "         [0.3644, 0.1617, 0.4740, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500]]])\n"
     ]
    }
   ],
   "source": [
    "decoder_score = torch.randn(batch_size, max(tgt_len), max(tgt_len))\n",
    "decoder_mask_score = decoder_score.masked_fill(invalid_decoder_tri_matrix, -1e9)\n",
    "decoder_mask_prob = F.softmax(decoder_mask_score,-1)\n",
    "print(decoder_mask_score)\n",
    "print(decoder_mask_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce62c1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# step7: 构建scaled self-attention\n",
    "def scaled_dot_product_attention(Q,K,V，atten_mask):\n",
    "    score = torch.bmm(Q,K.transpose(-2,-1))/torch.sqrt(model_dim)\n",
    "    mask_score = score.masked_fill(atten_mask, -1e9)\n",
    "    prob = F.softmax(mask_score,-1)\n",
    "    context = torch.bmm(prob, V)\n",
    "    return context"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}